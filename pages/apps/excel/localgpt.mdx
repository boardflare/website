---
title: Local GPT for Excel
---
import { DeviceInfo } from '@/components/DeviceInfo.jsx'
import { Callout } from 'nextra/components'

# Local GPT for Excel

<Callout type="warning" emoji="ðŸ§ª">
  **EXPERIMENTAL**:  Please provide [feedback](/company/support).
</Callout>

## Overview

Provides unlimited free and private AI inference by using a smaller language model, currently [Gemma2 2B](https://github.com/google-deepmind/gemma), that runs locally on your computer so your data never leaves Excel.  While not as fast and smart as ChatGPT, maybe it is all you need for simple tasks.  If you have a discrete GPU on your computer, it may be possible to run much larger and more powerful models. Please [let us know](/company/support) if you are interested in this.

Install from the Microsoft AppSource store at the link below, or directly from Excel.

<a href="https://appsource.microsoft.com/en-us/product/office/WA200007427?tab=Overview">
    <img 
        src="/images/MS_AppSource.png" 
        alt="AppSource"
        style={{ paddingTop: '10px', width: '150px' }}
    />
</a>

## Features

ðŸ†“ Unlimited free use.<br/>
ðŸ’» Processed locally on your computer.<br/>
ðŸ”’ No data is shared outside Excel.<br/>

## Requirements

The model used requires your browser supports [WebGPU](https://developer.mozilla.org/en-US/docs/Web/API/WebGPU_API) and the GPU supports `shader-f16`.  This is evaluated using the browser API with the following code:

```javascript
const adapter = await navigator.gpu.requestAdapter();
const supportsF16 = adapter?.features.has('shader-f16');
```

If `supportsF16` is not `true` the model will not run. 

Running that code right now in this browser yields the following result:

<Callout type="info" emoji="ðŸ’»">
  <DeviceInfo />
</Callout>

However, the browser you are using to view this web page may be different than the one that will run the add-in in Excel.  The main scenario where this is likely to occur is on Mac, where you might be using Chrome as your browser, but Excel uses Safari, which only has experimental support for WebGPU. 

The model also consumes roughly 2-3 GB of memory, so this will typically run on a computer with 8 GB.  Anything less and you most likely will run into memory issues.

## Functions

This app provides only one general function, as follows:

### LOCAL.GPT

=<code>BOARDFLARE.LOCAL.GPT (prompt, [options])</code><br/>
- `prompt`: Instructions for model (e.g. `"summarize: " & A1`).
- `options`: Placeholder for options, currently does nothing.

## Examples

Typically you will want a prompt that concatenates an instruction with a cell value, such as the following:

```excel
=BOARDFLARE.LOCAL.GPT("What is the problem this user is having?  Support Ticket: " & A1)
```

Or you could create a LAMBDA function like this:

```excel
=LAMBDA(
    ticket, 
    BOARDFLARE.LOCAL.GPT(
        "What is the problem this user is having? Support Ticket: " & ticket
    )
)
```

Then name it `GETPROBLEM`, so end-users could call it with `=GETPROBLEM(A1)`.  Generally you will want to use a named LAMBDA function to make it simpler for others to use and easier to update the prompt once for the entire workbook.


## Applications

Use for simple or less critical tasks that do not require a powerful AI model.

## Attribution

This add-in would not be possible without the following great open-source software projects:

- [WebLLM](https://github.com/mlc-ai/web-llm), see [license](https://github.com/mlc-ai/web-llm/blob/main/LICENSE)
- [Transformers.js](https://github.com/xenova/transformers.js), see [license](https://github.com/xenova/transformers.js/blob/main/LICENSE)